{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2c20378-b32b-4e96-99f9-5d075491561a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################################################################################\n",
      "\n",
      "Caenorhabditis elegans/BP.csv\n",
      "train 696\n",
      "val 78\n",
      "tst 87\n",
      "train 697\n",
      "val 78\n",
      "tst 86\n",
      "train 697\n",
      "val 78\n",
      "tst 86\n",
      "train 697\n",
      "val 78\n",
      "tst 86\n",
      "train 697\n",
      "val 78\n",
      "tst 86\n",
      "train 697\n",
      "val 78\n",
      "tst 86\n",
      "train 697\n",
      "val 78\n",
      "tst 86\n",
      "train 697\n",
      "val 78\n",
      "tst 86\n",
      "train 697\n",
      "val 78\n",
      "tst 86\n",
      "train 697\n",
      "val 78\n",
      "tst 86\n",
      "####################################################################################################\n",
      "\n",
      "Caenorhabditis elegans/BPCC.csv\n",
      "train 696\n",
      "val 78\n",
      "tst 87\n",
      "train 697\n",
      "val 78\n",
      "tst 86\n",
      "train 697\n",
      "val 78\n",
      "tst 86\n",
      "train 697\n",
      "val 78\n",
      "tst 86\n",
      "train 697\n",
      "val 78\n",
      "tst 86\n",
      "train 697\n",
      "val 78\n",
      "tst 86\n",
      "train 697\n",
      "val 78\n",
      "tst 86\n",
      "train 697\n",
      "val 78\n",
      "tst 86\n",
      "train 697\n",
      "val 78\n",
      "tst 86\n",
      "train 697\n",
      "val 78\n",
      "tst 86\n",
      "####################################################################################################\n",
      "\n",
      "Caenorhabditis elegans/BPMF.csv\n",
      "train 696\n",
      "val 78\n",
      "tst 87\n",
      "train 697\n",
      "val 78\n",
      "tst 86\n",
      "train 697\n",
      "val 78\n",
      "tst 86\n",
      "train 697\n",
      "val 78\n",
      "tst 86\n",
      "train 697\n",
      "val 78\n",
      "tst 86\n",
      "train 697\n",
      "val 78\n",
      "tst 86\n",
      "train 697\n",
      "val 78\n",
      "tst 86\n",
      "train 697\n",
      "val 78\n",
      "tst 86\n",
      "train 697\n",
      "val 78\n",
      "tst 86\n",
      "train 697\n",
      "val 78\n",
      "tst 86\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 50\u001b[0m\n\u001b[0;32m     48\u001b[0m allpath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00morganism\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(allpath):\n\u001b[1;32m---> 50\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mallpath\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[0;32m     51\u001b[0m     \u001b[38;5;66;03m# Dividir os dados em conjunto de dados de treino e teste\u001b[39;00m\n\u001b[0;32m     53\u001b[0m     X \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongevity influence\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1919\u001b[0m     (\n\u001b[0;32m   1920\u001b[0m         index,\n\u001b[0;32m   1921\u001b[0m         columns,\n\u001b[0;32m   1922\u001b[0m         col_dict,\n\u001b[1;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[0;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2053\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m<frozen codecs>:331\u001b[0m, in \u001b[0;36mgetstate\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import arff\n",
    "import os\n",
    "\n",
    "organisms = ['Caenorhabditis elegans', 'Drosophila melanogaster', 'Mus musculus', 'Saccharomyces cerevisiae']\n",
    "organismsMap = {'Caenorhabditis elegans': 'worm', 'Drosophila melanogaster': 'fly', 'Mus musculus': 'mouse', 'Saccharomyces cerevisiae': 'yeast'}\n",
    "\n",
    "# Definindo o número de folds\n",
    "num_folds = 10\n",
    "kf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Função para salvar dados em arquivos ARFF\n",
    "def salvar_arquivo_arff(nome_arquivo, dados, atributos, relation):\n",
    "    with open(nome_arquivo, 'w') as f:\n",
    "        arff.dump({\n",
    "            'relation': relation,\n",
    "            'attributes': [(col, 'REAL') for col in atributos],\n",
    "            'data': dados\n",
    "        }, f)\n",
    "\n",
    "# Função para criar e salvar os folds\n",
    "def create_folds_arff(X, y, relation, org, val):\n",
    "    for fold, (train_index, test_index) in enumerate(kf.split(X, y)):\n",
    "        # Dividindo o fold em treino e teste\n",
    "        train_df = df.iloc[train_index[:int(len(train_index) * 0.9)]]\n",
    "        val_df = df.iloc[train_index[int(len(train_index) * 0.9):]]\n",
    "        test_df = df.iloc[test_index[:]]\n",
    "        print(\"train\", len(train_df))\n",
    "        print(\"val\", len(val_df))\n",
    "        print(\"tst\", len(test_index))\n",
    "\n",
    "        # Salvando os dados em arquivos ARFF           \n",
    "        traName = f\"{organismsMap[org]}-{path.split(\".\")[0]}_fold_{fold}_tra\"\n",
    "        valName = f\"{organismsMap[org]}-{path.split(\".\")[0]}_fold_{fold}_val\"\n",
    "        tstName = f\"{organismsMap[org]}-{path.split(\".\")[0]}_fold_{fold}_tst\"\n",
    "\n",
    "        print(traName)\n",
    "        print(valName)\n",
    "        print(tstName)\n",
    "        \n",
    "        # salvar_arquivo_arff(f\"{org}/folds/{path.split(\".\")[0]}/{traName}.arff\", train_df.values, train_df.columns, relation=traName)\n",
    "        # salvar_arquivo_arff(f\"{org}/folds/{path.split(\".\")[0]}/{valName}.arff\", val_df.values, val_df.columns, relation=valName)\n",
    "        # salvar_arquivo_arff(f\"{org}/folds/{path.split(\".\")[0]}/{tstName}.arff\", test_df.values, test_df.columns, relation=tstName)\n",
    "        \n",
    "for organism in organisms:\n",
    "    for path in os.listdir(f\"{organism}\"):\n",
    "            allpath = f\"{organism}/{path}\"\n",
    "            if os.path.isfile(allpath):\n",
    "                df = pd.read_csv(allpath)  \n",
    "                # Dividir os dados em conjunto de dados de treino e teste\n",
    "                \n",
    "                X = df.drop('longevity influence', axis=1)\n",
    "                y = df['longevity influence']\n",
    "                \n",
    "                print(\"#\" * 100 + \"\\n\")\n",
    "                print(allpath)\n",
    "                # print(f\"Estatísticas gerais do conjunto de dados {organism} e {path.split(\".\")[0]}\")\n",
    "                # print(f\"\\n Quantidade de Instâncias: {len(df.values)}  Quantidade de Atributos: {len(df.columns)}\")\n",
    "                proLongevity = len(df[df['longevity influence'] == 1])\n",
    "                antiLongevity = len(df[df['longevity influence'] == 0])\n",
    "                percentPro = proLongevity / (proLongevity + antiLongevity) * 100\n",
    "                # print(f\"\\n Quantidade Pró-longevidade: {proLongevity}  Quantidade de Anti-longevidade: {antiLongevity} \\n\")\n",
    "                # print(f\"Porcentagem de Pró-longevidade: {percentPro:.4f} \\n\")         \n",
    "                \n",
    "                create_folds_arff(X, y, relation=path, org=organism, val=False)\n",
    "                \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab48b5f-97bd-42d1-a35a-5a9b146cf308",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2454bf-9c71-44db-90c1-29432a3bf889",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
